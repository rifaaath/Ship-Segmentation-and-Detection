{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "TRAINING_VALIDATION_RATIO = 0.2\n",
    "WORKING_DIR = './working'\n",
    "INPUT_DIR = './input'\n",
    "OUTPUT_DIR = './output'\n",
    "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n",
    "print(LOGS_DIR)\n",
    "TRAIN_DATA_PATH = os.path.join(INPUT_DIR, 'train_v2')\n",
    "print(TRAIN_DATA_PATH)\n",
    "TEST_DATA_PATH = os.path.join(INPUT_DIR, 'test_v2')\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(INPUT_DIR, 'sample_submission_v2.csv')\n",
    "TRAIN_SHIP_SEGMENTATIONS_PATH = os.path.join(INPUT_DIR, 'train_ship_segmentations_v2.csv')\n",
    "MASK_RCNN_PATH = os.path.join('./working',\"Mask_RCNN-master\")\n",
    "COCO_WEIGHTS_PATH = os.path.join(WORKING_DIR, \"mask_rcnn_coco.h5\")\n",
    "SHIP_CLASS_NAME = 'ship'\n",
    "IMAGE_WIDTH = 768\n",
    "IMAGE_HEIGHT = 768\n",
    "SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "\n",
    "test_ds = os.listdir(TEST_DATA_PATH)\n",
    "train_ds = os.listdir(TRAIN_DATA_PATH)\n",
    "\n",
    "print('Working Dir:', WORKING_DIR, os.listdir(WORKING_DIR))\n",
    "print('Input Dir:', INPUT_DIR, os.listdir(INPUT_DIR))\n",
    "print('train dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(train_ds)))\n",
    "print('test dataset from: {}, {}'.format(TRAIN_DATA_PATH, len(test_ds)))\n",
    "print(TRAIN_SHIP_SEGMENTATIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11c19903f97a53de869d94a468209dd92fc2f267"
   },
   "outputs": [],
   "source": [
    "masks = pd.read_csv(TRAIN_SHIP_SEGMENTATIONS_PATH)\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb81ee007e820e6711069f8f3895812e59b24533"
   },
   "outputs": [],
   "source": [
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "def rle_encode(img):\n",
    "  \n",
    "    pixels = img.T.flatten() \n",
    "  \n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    " \n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "  \n",
    "    runs[1::2] -= runs[::2]\n",
    "   \n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=SHAPE):\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def masks_as_image(in_mask_list, shape=SHAPE):\n",
    "    all_masks = np.zeros(shape, dtype = np.int16)\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n",
    "\n",
    "def shows_decode_encode(image_id, path=TRAIN_DATA_PATH):\n",
    "   \n",
    "    fig, axarr = plt.subplots(1, 3, figsize = (10, 5))\n",
    "    img_0 = imread(os.path.join(path, image_id))\n",
    "    axarr[0].imshow(img_0)\n",
    "    axarr[0].set_title(image_id)\n",
    "    rle_1 = masks.query('ImageId==\"{}\"'.format(image_id))['EncodedPixels']\n",
    "    img_1 = masks_as_image(rle_1)\n",
    "    axarr[1].imshow(img_1[:, :, 0])\n",
    "    axarr[1].set_title('Ship Mask')\n",
    "    rle_2 = multi_rle_encode(img_1)\n",
    "    img_2 = masks_as_image(rle_2)\n",
    "    axarr[2].imshow(img_0)\n",
    "    axarr[2].imshow(img_2[:, :, 0], alpha=0.3)\n",
    "    axarr[2].set_title('Encoded & Decoded Mask')\n",
    "    plt.show()\n",
    "    print(image_id , ' Check Decoding->Encoding',\n",
    "          'RLE_0:', len(rle_1), '->',\n",
    "          'RLE_1:', len(rle_2))\n",
    "\n",
    "shows_decode_encode('000155de5.jpg')\n",
    "shows_decode_encode('00003e153.jpg')\n",
    "print('It could be different when there is no mask.')\n",
    "shows_decode_encode('00021ddc3.jpg')\n",
    "print('It could be different when there are masks overlapped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c312f477005641cd3d4a4eeb28ca92ad668ab3c"
   },
   "source": [
    "## Split Test and Validation datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5f7da5d8ff0061fc809ef9edb9698e228d6f762e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m unique_img_ids \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mImageId\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mships\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m unique_img_ids[\u001b[39m'\u001b[39m\u001b[39mRleMaskList\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mImageId\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mEncodedPixels\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlist\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m unique_img_ids \u001b[39m=\u001b[39m unique_img_ids\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ameen/tensorflow-test/kaggle/ship_segmentation.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/groupby/generic.py:254\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[1;32m    249\u001b[0m     _apply_docs[\u001b[39m\"\u001b[39m\u001b[39mtemplate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    250\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, examples\u001b[39m=\u001b[39m_apply_docs[\u001b[39m\"\u001b[39m\u001b[39mseries_examples\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m )\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1549\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1548\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1549\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[1;32m   1550\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1551\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_selection_context():\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1601\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1566\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1572\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1573\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1601\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[1;32m   1602\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1603\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/series.py:768\u001b[0m, in \u001b[0;36mSeries.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    765\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39m    Return the length of the Series.\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/internals/base.py:48\u001b[0m, in \u001b[0;36mDataManager.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems)\n",
      "File \u001b[0;32m~/tensorflow-test/env/lib/python3.8/site-packages/pandas/core/internals/managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_single_block\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    235\u001b[0m     \u001b[39m# Assumes we are 2D; overridden by SingleBlockManager\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 238\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mitems\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[1;32m    240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m0\u001b[39m]\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_has_no_reference\u001b[39m(\u001b[39mself\u001b[39m, i: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda encoded_pixels: 1 if isinstance(encoded_pixels, str) else 0)\n",
    "\n",
    "start_time = time.time()\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'})\n",
    "unique_img_ids['RleMaskList'] = masks.groupby('ImageId')['EncodedPixels'].apply(list)\n",
    "unique_img_ids = unique_img_ids.reset_index()\n",
    "end_time = time.time() - start_time\n",
    "print(\"unique_img_ids groupby took: {}\".format(end_time))\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['ships'] > 0]\n",
    "unique_img_ids['ships'].hist()\n",
    "unique_img_ids.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77fa915c8c928f19a27e32e656d119ce465d049b"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, val_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = TRAINING_VALIDATION_RATIO, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "print(train_ids.shape[0], 'training masks')\n",
    "print(val_ids.shape[0], 'validation masks')\n",
    "train_ids['ships'].hist()\n",
    "val_ids['ships'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# cifar = tf.keras.datasets.cifar100\n",
    "# (x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "# model = tf.keras.applications.ResNet50(\n",
    "#     include_top=True,\n",
    "#     weights=None,\n",
    "#     input_shape=(32, 32, 3),\n",
    "#     classes=100,)\n",
    "\n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "# model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bf4b1b2e24e9d212210d635f17a15eeb3e11dc0"
   },
   "outputs": [],
   "source": [
    "\n",
    "UPDATE_MASK_RCNN = False\n",
    "\n",
    "if UPDATE_MASK_RCNN:\n",
    "    !rm -rf {MASK_RCNN_PATH}\n",
    "\n",
    "if not os.path.exists(MASK_RCNN_PATH):\n",
    "    print(\"Not found\")\n",
    "\n",
    "print(os.path.curdir)\n",
    "#os.chdir(MASK_RCNN_PATH)\n",
    "sys.path.append(MASK_RCNN_PATH)  \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5767146c1a5ab4663dce7e5e59bf00792b840935"
   },
   "outputs": [],
   "source": [
    "class AirbusShipDetectionChallengeDataset(utils.Dataset):\n",
    "    def __init__(self, image_file_dir, ids, masks, image_width=IMAGE_WIDTH, image_height=IMAGE_HEIGHT):\n",
    "        super().__init__(self)\n",
    "        self.image_file_dir = image_file_dir\n",
    "        self.ids = ids\n",
    "        self.masks = masks\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        \n",
    "        self.add_class(SHIP_CLASS_NAME, 1, SHIP_CLASS_NAME)\n",
    "        self.load_dataset()\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        for index, row in self.ids.iterrows():\n",
    "            image_id = row['ImageId']\n",
    "            image_path = os.path.join(self.image_file_dir, image_id)\n",
    "            rle_mask_list = row['RleMaskList']\n",
    "            self.add_image(\n",
    "                SHIP_CLASS_NAME,\n",
    "                image_id=image_id,\n",
    "                path=image_path,\n",
    "                width=self.image_width, height=self.image_height,\n",
    "                rle_mask_list=rle_mask_list)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        rle_mask_list = info['rle_mask_list']\n",
    "        mask_count = len(rle_mask_list)\n",
    "        mask = np.zeros([info['height'], info['width'], mask_count],\n",
    "                        dtype=np.uint8)\n",
    "        i = 0\n",
    "        for rel in rle_mask_list:\n",
    "            if isinstance(rel, str):\n",
    "                np.copyto(mask[:,:,i], rle_decode(rel))\n",
    "            i += 1\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "    \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        if info['source'] == SHIP_CLASS_NAME:\n",
    "            return info['path']\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d65d5335db367f346c2b8c71859a102c2ca44884"
   },
   "outputs": [],
   "source": [
    "class AirbusShipDetectionChallengeGPUConfig(Config):\n",
    "    NAME = 'METAL'\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    NUM_CLASSES = 2  \n",
    "    IMAGE_MIN_DIM = IMAGE_WIDTH\n",
    "    IMAGE_MAX_DIM = IMAGE_WIDTH\n",
    "    STEPS_PER_EPOCH = 300\n",
    "    VALIDATION_STEPS = 50\n",
    "    SAVE_BEST_ONLY = True\n",
    "    DETECTION_MIN_CONFIDENCE = 0.95\n",
    "    DETECTION_NMS_THRESHOLD = 0.05\n",
    "\n",
    "config = AirbusShipDetectionChallengeGPUConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "216e602cbe93af42697e9a3783d814fd086726c1"
   },
   "source": [
    "## Prepare and load training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69e444fa1d9061b07175fd833120f42527d33388"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "dataset_train = AirbusShipDetectionChallengeDataset(image_file_dir=TRAIN_DATA_PATH, ids=train_ids, masks=masks)\n",
    "dataset_train.prepare()\n",
    "dataset_val = AirbusShipDetectionChallengeDataset(image_file_dir=TRAIN_DATA_PATH, ids=val_ids, masks=masks)\n",
    "dataset_val.prepare()\n",
    "\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 3)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names, limit=1)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print(\"dataset prepare: {}\".format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cbafccaad2be91cc9b57d841b6557b56f6ba8f9"
   },
   "source": [
    "## Load pre-trained wieghts\n",
    "Pre-trained weights for MS COCO is loaded to provide a better straing point for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "699ad18606e3c2b9d430b967c984f1965514d66b"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=WORKING_DIR)\n",
    "\n",
    "import errno\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "try:\n",
    "    weights_path = model.find_last()\n",
    "    load_weights = True\n",
    "except FileNotFoundError:\n",
    "    load_weights = True\n",
    "    weights_path = COCO_WEIGHTS_PATH\n",
    "    utils.download_trained_weights(weights_path)\n",
    "    \n",
    "if load_weights:\n",
    "    print(\"Loading weights: \", weights_path)\n",
    "    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "                \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print(\"loading weights: {}\".format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c376a3ba3bcc0127a903383e9656f726c17d479"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f00d812de48f9cbc99b9db7ccec54dbff643ac64"
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()    \n",
    "model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE * 1.5,\n",
    "            epochs=2,\n",
    "            layers='all')\n",
    "end_time = time.time() - start_time\n",
    "print(\"Train model: {}\".format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca6f0db4d5a282caf76adcc9fd27e600fbbd28b9"
   },
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62d99adbb8c5b7eaf19b1f731acbb01f87b24553"
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(AirbusShipDetectionChallengeGPUConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "infer_model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=WORKING_DIR)\n",
    "\n",
    "model_path = infer_model.find_last()\n",
    "\n",
    "print(\"Loading weights from \", model_path)\n",
    "infer_model.load_weights(model_path, by_name=True)\n",
    "\n",
    "image_id = np.random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))\n",
    "\n",
    "results = infer_model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'])\n",
    "\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 20)\n",
    "APs = []\n",
    "inference_start = time.time()\n",
    "for image_id in image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    results = infer_model.detect([image], verbose=1)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'])\n",
    "\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "\n",
    "inference_end = time.time()\n",
    "print('Inference Time: %0.2f Minutes'%((inference_end - inference_start)/60))\n",
    "print(\"mAP: \", np.mean(APs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
